{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import sigmoid\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "from utils.vtk import render_scan\n",
    "from utils.image import load_img, img_to_array, cubify_scan, calc_dist_map\n",
    "from utils.performance import calc_confusion_matrix\n",
    "\n",
    "from losses.surface import surface_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "setup = {\n",
    "    'struct': 'lateral_ventricle', 'arch': 'Unet', 'loss_fn': 'binary',\n",
    "    'batch_size': 4, 'filters': 16, 'batch_norm': True,\n",
    "    'optimizer_fn': 'Adam', 'lr': 0.001, 'threshold': 0.5,\n",
    "    'input_shape': (192, 256, 1), 'epochs': 50\n",
    "}\n",
    "\n",
    "collection_name = 'mindboggle_84_Nx192x256_lateral_ventricle'\n",
    "dataset_dir = os.path.join('/home/filip/Projekty/ML/datasets', collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Unet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=(3,3), padding=(1,1)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=(3,3), padding=(1,1)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, n_channels, n_filters, n_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(n_channels, n_filters)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        \n",
    "        self.conv2 = ConvBlock(n_filters, n_filters*2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        \n",
    "        self.conv3 = ConvBlock(n_filters*2, n_filters*4)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        \n",
    "        self.conv4 = ConvBlock(n_filters*4, n_filters*8)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        \n",
    "        self.bridge5 = ConvBlock(n_filters*8, n_filters*16)\n",
    "        \n",
    "        self.up6 = nn.ConvTranspose2d(n_filters*16, n_filters*8, kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv6 = ConvBlock(n_filters*16, n_filters*8)\n",
    "        \n",
    "        self.up7 = nn.ConvTranspose2d(n_filters*8, n_filters*4, kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv7 = ConvBlock(n_filters*8, n_filters*4)\n",
    "        \n",
    "        self.up8 = nn.ConvTranspose2d(n_filters*4, n_filters*2, kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv8 = ConvBlock(n_filters*4, n_filters*2)\n",
    "        \n",
    "        self.up9 = nn.ConvTranspose2d(n_filters*2, n_filters, kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv9 = ConvBlock(n_filters*2, n_filters)\n",
    "        \n",
    "        self.outputs = nn.Conv2d(n_filters, n_classes, kernel_size=(1,1))\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        conv1 = self.conv1(x)\n",
    "        pool1 = self.pool1(conv1)\n",
    "        \n",
    "        conv2 = self.conv2(pool1)\n",
    "        pool2 = self.pool2(conv2)\n",
    "        \n",
    "        conv3 = self.conv3(pool2)\n",
    "        pool3 = self.pool3(conv3)\n",
    "        \n",
    "        conv4 = self.conv4(pool3)\n",
    "        pool4 = self.pool4(conv4)\n",
    "        \n",
    "        bridge5 = self.bridge5(pool4)\n",
    "        \n",
    "        up6 = self.up6(bridge5)\n",
    "        cat6 = torch.cat([up6, conv4], dim=1)\n",
    "        conv6 = self.conv6(cat6)\n",
    "        \n",
    "        up7 = self.up7(conv6)\n",
    "        cat7 = torch.cat([up7, conv3], dim=1)\n",
    "        conv7 = self.conv7(cat7)\n",
    "        \n",
    "        up8 = self.up8(conv7)\n",
    "        cat8 = torch.cat([up8, conv2], dim=1)\n",
    "        conv8 = self.conv8(cat8)\n",
    "        \n",
    "        up9 = self.up9(conv8)\n",
    "        cat9 = torch.cat([up9, conv1], dim=1)\n",
    "        conv9 = self.conv9(cat9)\n",
    "        \n",
    "        x = self.outputs(conv9)\n",
    "        \n",
    "        return sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset2d(Dataset):\n",
    "    def __init__(self, X_tensor, y_tensor):\n",
    "        self.X = X_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_files = sorted(\n",
    "    glob.glob(\n",
    "        os.path.join(dataset_dir, 'train', 'images', '*.png')\n",
    "    )[:]\n",
    ")\n",
    "y_files = sorted(\n",
    "    glob.glob(\n",
    "        os.path.join(dataset_dir, 'train', 'labels', '*.png')\n",
    "    )[:]\n",
    ")\n",
    "\n",
    "X_images = np.stack([img_to_array(load_img(filename)) for filename in X_files])\n",
    "y_images = np.stack([img_to_array(load_img(filename)) for filename in y_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_images, y_images, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "X_valid = torch.from_numpy(X_valid)\n",
    "y_valid = torch.from_numpy(y_valid)\n",
    "\n",
    "train_dataset = Dataset2d(X_train, y_train)\n",
    "val_dataset = Dataset2d(X_valid, y_valid)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=setup['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=setup['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(n_channels=1, n_filters=16, n_classes=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = surface_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=setup['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 50\n",
      "Time per epoch: 54.395 seconds\n",
      "Train. loss: 6.915209076709244\n",
      "Valid. loss: 0.005713049112068069\n",
      "---------------------------------------------------\n",
      "Epoch 2 / 50\n",
      "Time per epoch: 54.067 seconds\n",
      "Train. loss: 0.5821487852513911\n",
      "Valid. loss: 0.006149502332142043\n",
      "---------------------------------------------------\n",
      "Epoch 3 / 50\n",
      "Time per epoch: 54.472 seconds\n",
      "Train. loss: 0.18628107695925308\n",
      "Valid. loss: 0.002138805359971875\n",
      "---------------------------------------------------\n",
      "Epoch 4 / 50\n",
      "Time per epoch: 54.762 seconds\n",
      "Train. loss: 0.07733907402090683\n",
      "Valid. loss: 0.002834622932676857\n",
      "---------------------------------------------------\n",
      "Epoch 5 / 50\n",
      "Time per epoch: 54.785 seconds\n",
      "Train. loss: 0.04084676160320307\n",
      "Valid. loss: 0.0027389867442956703\n",
      "---------------------------------------------------\n",
      "Epoch 6 / 50\n",
      "Time per epoch: 55.749 seconds\n",
      "Train. loss: 0.021889229676767458\n",
      "Valid. loss: 0.0025590235946442736\n",
      "---------------------------------------------------\n",
      "Epoch 7 / 50\n",
      "Time per epoch: 55.382 seconds\n",
      "Train. loss: 0.012938454397895012\n",
      "Valid. loss: 0.002583891150049655\n",
      "---------------------------------------------------\n",
      "Epoch 8 / 50\n",
      "Time per epoch: 55.291 seconds\n",
      "Train. loss: 0.007540209121896099\n",
      "Valid. loss: 0.002338033348825129\n",
      "---------------------------------------------------\n",
      "Epoch 9 / 50\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(setup['epochs']):\n",
    "    print(f\"Epoch {epoch + 1} / {setup['epochs']}\")\n",
    "    start = time.time()\n",
    "    batch_losses = []\n",
    "    batch_val_losses = []\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        y_hat = model(X_batch)\n",
    "          \n",
    "        # calc distance and pass it to surface loss\n",
    "        y_batch_numpy = y_batch.cpu().numpy()\n",
    "        y_dist = np.array([calc_dist_map(y) for y in y_batch_numpy]).astype(np.float32)\n",
    "        y_dist = torch.from_numpy(y_dist).to(device)\n",
    "\n",
    "        loss = loss_fn(y_hat, y_dist)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            y_hat = model(X_batch)\n",
    "            \n",
    "            val_loss = loss_fn(y_hat, y_batch)\n",
    "            batch_val_losses.append(val_loss.item())\n",
    "        \n",
    "        \n",
    "    losses.append(np.mean(batch_losses))\n",
    "    val_losses.append(np.mean(batch_val_losses))\n",
    "    \n",
    "    print(f'Time per epoch: {(time.time() - start):.3f} seconds')\n",
    "    print(f'Train. loss:', np.mean(batch_losses))\n",
    "    print(f'Valid. loss:', np.mean(batch_val_losses))\n",
    "    print(f'---------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(setup['epochs']), losses, val_losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_files = sorted(\n",
    "    glob.glob(\n",
    "        os.path.join(dataset_dir, 'test', 'images', '*.png')\n",
    "    )[:]\n",
    ")\n",
    "y_files = sorted(\n",
    "    glob.glob(\n",
    "        os.path.join(dataset_dir, 'test', 'labels', '*.png')\n",
    "    )[:]\n",
    ")\n",
    "\n",
    "X_images = np.stack([img_to_array(load_img(filename)) for filename in X_files])\n",
    "y_images = np.stack([img_to_array(load_img(filename)) for filename in y_files])\n",
    "\n",
    "X_test = torch.from_numpy(X_images)\n",
    "y_test = torch.from_numpy(y_images)\n",
    "\n",
    "test_dataset = Dataset2d(X_test, y_test)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=setup['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_preds = list()\n",
    "scan_mask = list()\n",
    "\n",
    "for X_batch, y_batch in test_loader:\n",
    "    X_batch = X_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.cpu().numpy()\n",
    "        preds = (preds > setup['threshold']).astype(np.uint8)\n",
    "        scan_preds.append(preds.squeeze())\n",
    "        \n",
    "        mask = y_batch.cpu().numpy().squeeze().astype(np.uint8)\n",
    "        scan_mask.append(mask)\n",
    "        \n",
    "scan_preds = np.concatenate([img for img in scan_preds])\n",
    "scan_mask = np.concatenate([img for img in scan_mask])\n",
    "\n",
    "print('Preds shape:', scan_preds.shape)\n",
    "print('Mask shape:', scan_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = calc_confusion_matrix(scan_mask, scan_preds)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scan = cubify_scan(scan_preds, 256, 256, 192, 256)\n",
    "test_scan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_scan(test_scan, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
